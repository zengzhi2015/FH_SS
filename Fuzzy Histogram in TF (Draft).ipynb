{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "image_height = 240\n",
    "image_width = 320\n",
    "num_bin = 20+1\n",
    "bin_width = 1.0/(num_bin-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0], [0, 1], [0, 2], [0, 3]],\n",
       " [[1, 0], [1, 1], [1, 2], [1, 3]],\n",
       " [[2, 0], [2, 1], [2, 2], [2, 3]]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[[r,c] for c in range(0,4)] for r in range(0,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scope = tf.variable_scope('model', reuse=tf.AUTO_REUSE)\n",
    "input_scope = tf.variable_scope('input', reuse=tf.AUTO_REUSE)\n",
    "output_scope = tf.variable_scope('output', reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_scope:\n",
    "    # Build the model\n",
    "    fuzzy_histogram = tf.get_variable('fuzzy_histogram',\n",
    "                                      shape=[image_height, image_width, num_bin],\n",
    "                                      initializer=tf.constant_initializer(1.0),\n",
    "                                      trainable=False)\n",
    "    # Define updating mask\n",
    "    update_mask = tf.get_variable('update_mask',\n",
    "                                  shape=[image_height, image_width],\n",
    "                                  initializer=tf.constant_initializer(1.0),\n",
    "                                  trainable=False)\n",
    "    # Intermitent vars\n",
    "    data_position_in_histogram = tf.get_variable('data_position_in_histogram',\n",
    "                                                 shape=[image_height, image_width],\n",
    "                                                 trainable=False)\n",
    "    pre_index = tf.get_variable('previous_index_in_histogram',\n",
    "                                shape=[image_height, image_width],\n",
    "                                trainable=False)\n",
    "    pre_weight = tf.get_variable('previous_weight_in_histogram',\n",
    "                                 shape=[image_height, image_width],\n",
    "                                 trainable=False)\n",
    "    next_index = tf.get_variable('next_index_in_histogram',\n",
    "                                 shape=[image_height, image_width],\n",
    "                                 trainable=False)\n",
    "    next_weight = tf.get_variable('next_weight_in_histogram',\n",
    "                                  shape=[image_height, image_width],\n",
    "                                  trainable=False)\n",
    "    max_bin_value = tf.get_variable('max_bin_value',\n",
    "                                    shape=[image_height, image_width],\n",
    "                                    trainable=False)\n",
    "    # Intermitent constants\n",
    "    indexing_constant = tf.constant([[[r,c] for c in range(image_width)] for r in range(image_height)],name='indexing_constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with input_scope:\n",
    "    # Define the input image\n",
    "    input_image = tf.placeholder(tf.float32, \n",
    "                                 shape=[image_height,image_width], \n",
    "                                 name='image')\n",
    "    # Define the iground truth\n",
    "    label = tf.placeholder(tf.float32, \n",
    "                           shape=[image_height,image_width], \n",
    "                           name='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with output_scope:\n",
    "    # Define the raw output \n",
    "    raw_segmentation = tf.get_variable('compatibility',\n",
    "                             shape=[image_height, image_width],\n",
    "                             trainable=False)\n",
    "    # Define the synthesis result \n",
    "    synthesis_result = tf.get_variable('synthesis',\n",
    "                             shape=[image_height, image_width],\n",
    "                             trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/fuzzy_histogram:0 (240, 320, 21)\n",
      "model/update_mask:0 (240, 320)\n",
      "model/data_position_in_histogram:0 (240, 320)\n",
      "model/previous_index_in_histogram:0 (240, 320)\n",
      "model/previous_weight_in_histogram:0 (240, 320)\n",
      "model/next_index_in_histogram:0 (240, 320)\n",
      "model/next_weight_in_histogram:0 (240, 320)\n",
      "model/max_bin_value:0 (240, 320)\n",
      "output/compatibility:0 (240, 320)\n",
      "output/synthesis:0 (240, 320)\n"
     ]
    }
   ],
   "source": [
    "for var in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES ):\n",
    "    print(var.name,var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/indexing_constant:0 (240, 320, 2)\n"
     ]
    }
   ],
   "source": [
    "print(indexing_constant.name,indexing_constant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/image\n",
      "input/truth\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    if op.type == \"Placeholder\":\n",
    "        print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "def initialize_sess(graph=tf.get_default_graph()):\n",
    "    sess = tf.Session(graph=graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define histogram checking\n",
    "def histogram_checking(sess, gray_float_image):\n",
    "    '''\n",
    "    Inputs:\n",
    "        data_to_check: [height, width], float (from 0.0 to 1.0)\n",
    "        histogram_to_use: [height, width, num_bins], float\n",
    "    Outputs:\n",
    "        result: [height, width], float\n",
    "    '''\n",
    "    sess.run(data_position_in_histogram.assign(input_image/bin_width),feed_dict={input_image: gray_float_image})\n",
    "    sess.run(pre_index.assign(tf.floor(data_position_in_histogram)))\n",
    "    sess.run(pre_weight.assign(data_position_in_histogram-pre_index))\n",
    "    sess.run(next_index.assign(pre_index+1))\n",
    "    sess.run(next_weight.assign(next_index-data_position_in_histogram))\n",
    "    sess.run(raw_segmentation.assign(tf.add(tf.multiply(tf.gather_nd(fuzzy_histogram,\n",
    "                                                                     tf.concat([indexing_constant, tf.expand_dims(pre_index, -1)], -1)),\n",
    "                                                        pre_weight),\n",
    "                                            tf.multiply(tf.gather_nd(fuzzy_histogram,\n",
    "                                                                     tf.concat([indexing_constant, tf.expand_dims(next_index, -1)], -1)),\n",
    "                                                        next_weight))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_synthesis(sess):\n",
    "    # The following can be replaced by avr_pooling\n",
    "    blurred_mask = cv2.medianBlur(sess.run(raw_segmentation.value()),9)\n",
    "    sess.run(synthesis_result.assign(blurred_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight_calculation(sess):\n",
    "    # a*y^5/(x+b) a = 0.0792; b = 0.1585\n",
    "    sess.run(update_mask.assign(0.0792*synthesis_result**5/(raw_segmentation+0.1585)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_histogram(sess):\n",
    "    sess.run(tf.scatter_update(fuzzy_histogram,\n",
    "                               indices=tf.concat([indexing_constant, tf.expand_dims(pre_index, -1)],\n",
    "                               updates=tf.add(tf.multiply(pre_weight,update_mask),\n",
    "                                              tf.gather_nd(fuzzy_histogram,\n",
    "                                                           tf.concat([indexing_constant, tf.expand_dims(pre_index, -1)], -1))))))\n",
    "    sess.run(tf.scatter_update(fuzzy_histogram,\n",
    "                               indices=tf.concat([indexing_constant, tf.expand_dims(next_index, -1)],\n",
    "                               updates=tf.add(tf.multiply(next_weight,update_mask),\n",
    "                                              tf.gather_nd(fuzzy_histogram,\n",
    "                                                           tf.concat([indexing_constant, tf.expand_dims(next_index, -1)], -1))))))\n",
    "    sess.run(max_bin_value.assign(tf.reduce_max(fuzzy_histogram,axis=-1)))\n",
    "    sess.run(fuzzy_histogram.assign(tf.divide(fuzzy_histogram,\n",
    "                                              tf.tile(tf.expand_dims(max_bin_value, -1),\n",
    "                                                      [1, 1, num_bin]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'F:\\\\dataset2014\\\\dataset\\\\baseline\\\\highway\\\\input\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = initialize_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m                 as_ref=input_arg.is_ref)\n\u001b[0m\u001b[0;32m    456\u001b[0m             if input_arg.number_attr and len(\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor\u001b[1;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m             ctx=ctx))\n\u001b[0m\u001b[0;32m   1102\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1035\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m    880\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"ExpandDims:0\", shape=(240, 320, 1), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-adc9f5973838>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cv_float_gray_image'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv_float_gray_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mhistogram_checking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_float_gray_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtemp_synthesis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'synthesis_image'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msynthesis_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-a2abf0cf7c04>\u001b[0m in \u001b[0;36mhistogram_checking\u001b[1;34m(sess, gray_float_image)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdata_position_in_histogram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     sess.run(raw_segmentation.assign(tf.add(tf.multiply(tf.gather_nd(fuzzy_histogram,\n\u001b[1;32m---> 16\u001b[1;33m                                                                      tf.concat([indexing_constant, tf.expand_dims(pre_index, -1)], -1)),\n\u001b[0m\u001b[0;32m     17\u001b[0m                                                         pre_weight),\n\u001b[0;32m     18\u001b[0m                                             tf.multiply(tf.gather_nd(fuzzy_histogram,\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1173\u001b[0m               tensor_shape.scalar())\n\u001b[0;32m   1174\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m_concat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m    775\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m--> 777\u001b[1;33m         \"ConcatV2\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[0;32m    778\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    481\u001b[0m                                 (prefix, dtype.name))\n\u001b[0;32m    482\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s that don't all match.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m               \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s that are invalid.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match."
     ]
    }
   ],
   "source": [
    "for i_train in range(1,20):\n",
    "    cv_BGR_image = cv2.imread(image_folder + 'in{0:06d}'.format(i_train) + '.jpg')\n",
    "    cv_gray_image = cv2.cvtColor(cv_BGR_image, cv2.COLOR_BGR2GRAY)\n",
    "    cv_float_gray_image = cv_gray_image.astype('float')/255\n",
    "    cv2.imshow('cv_float_gray_image',cv_float_gray_image)\n",
    "    cv2.waitKey(-1)\n",
    "    histogram_checking(sess, cv_float_gray_image)\n",
    "    temp_synthesis(sess)\n",
    "    cv2.imshow('synthesis_image',sess.run(synthesis_result.value()))\n",
    "    cv2.waitKey(-1)\n",
    "    # update_weight_calculation(sess)\n",
    "    update_histogram(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_BGR_image = cv2.imread(image_folder + 'in{0:06d}'.format(1) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gray_image = cv2.cvtColor(cv_BGR_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gray_image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gray_image.dtype == 'uint8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_float_gray_image = cv_gray_image.astype('float')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_float_gray_image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11764705882352941"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_float_gray_image[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\dataset2014\\\\dataset\\\\baseline\\\\highway\\\\input\\\\in000015.jpg'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder + 'in{0:06d}'.format(15) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000013'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{0:06d}'.format(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     13'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0:>7d}\".format(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[[[1. 1. 1.]\n",
      "  [2. 2. 2.]]\n",
      "\n",
      " [[3. 3. 3.]\n",
      "  [4. 4. 4.]]]\n",
      "[[[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[1. 2.]\n",
      "  [3. 4.]]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "temp_A = tf.constant([[ 1.,  2.], [ 3. , 4.]])\n",
    "temp_B = tf.tile(tf.expand_dims(temp_A, -1),[1, 1, 3])\n",
    "temp_C = tf.expand_dims(tf.ones([temp_A.shape[0],1]), 1) * temp_A\n",
    "with tf.Session() as sess:\n",
    "    print(temp_A.eval())\n",
    "    print(temp_B.eval())\n",
    "    print(temp_C.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Slice assignment\n",
    "tf.reset_default_graph()\n",
    "temp_x = tf.Variable([2.0,3.0,4.0], name='temp_x')\n",
    "temp_index = [0,2]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([temp_x,]))\n",
    "    sess.run(tf.scatter_update(temp_x,indices=temp_index,updates=temp_index))\n",
    "    print(temp_x.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4]\n"
     ]
    }
   ],
   "source": [
    "temp_np_x = np.array([2,3,4])\n",
    "print(temp_np_x[temp_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*3**2*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32. 243.]\n",
      "[10. 15.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "temp_x = tf.constant([2.0,3.0], name='temp_x')\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.pow(temp_x, 5)))\n",
    "    print(sess.run(temp_x*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[3. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "temp_a = tf.Variable([1.0,2.0,3.0])\n",
    "\n",
    "# temp_b = temp_a/2\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([temp_a,]))\n",
    "    print(sess.run(temp_a.value()))\n",
    "    print(type(sess.run(temp_a.value())))\n",
    "    print(type(temp_a.eval()))\n",
    "    temp_x = sess.run(temp_a.value())\n",
    "    temp_T = temp_a.eval()\n",
    "    sess.run(temp_a.assign([3,2,1]))\n",
    "    print(temp_a.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "1.0\n",
      "11.0\n",
      "11.0\n",
      "12.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "temp_x = tf.Variable(10.0, name='temp_x')\n",
    "temp_y = tf.Variable(1.0, name='temp_y')\n",
    "temp_z = temp_x+temp_y\n",
    "temp_assign_op = temp_x.assign(temp_z)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([temp_x,temp_y]))\n",
    "    print(temp_x.eval())\n",
    "    print(temp_y.eval())\n",
    "    print(temp_z.eval())\n",
    "    print(temp_assign_op.eval())\n",
    "    print(temp_assign_op.eval())\n",
    "    print(temp_x.eval())\n",
    "    tf.summary.FileWriter('Logs', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_x:0 ()\n",
      "temp_y:0 ()\n"
     ]
    }
   ],
   "source": [
    "for var in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES ):\n",
    "    print(var.name,var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_x/initial_value\n",
      "temp_x\n",
      "temp_x/Assign\n",
      "temp_x/read\n",
      "temp_y/initial_value\n",
      "temp_y\n",
      "temp_y/Assign\n",
      "temp_y/read\n",
      "add\n",
      "Assign\n",
      "init\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "temp_x = tf.placeholder(tf.float32, name='temp_x')\n",
    "temp_a = tf.Variable(0.0, name='temp_a')\n",
    "temp_b = tf.Variable(0.0, name='temp_b')\n",
    "temp_c = tf.Variable(0.0, name='temp_c')\n",
    "temp_assign_a = temp_a.assign(temp_x+1)\n",
    "temp_assign_b = temp_b.assign(temp_a+1)\n",
    "temp_assign_c = temp_c.assign(temp_b+1)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.variables_initializer([temp_a,temp_b,temp_c]))\n",
    "    print(temp_a.eval())\n",
    "    print(temp_b.eval())\n",
    "    print(temp_c.eval())\n",
    "    print(temp_assign_c.eval())\n",
    "    print(temp_a.eval())\n",
    "    print(temp_b.eval())\n",
    "    print(temp_c.eval())\n",
    "    print(sess.run(temp_assign_a, feed_dict={temp_x: 7}))\n",
    "    tf.summary.FileWriter('Logs', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_synthesis():\n",
    "    cv2.medianBlur(raw_segmentation.value,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
